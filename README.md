# visual-audio cross modal retrieval task

Code for Paper: DCLMA: Deep Correlation Learning with Multi-modal Attention for Visual-Audio Retrieval.

## Data
Download routines for the datasets are not provided in the repository. Please download and prepare the datasets yourself according to our paper:
- [VEGAS Dataset](https://drive.google.com/file/d/1EjRDkgiXzAR8thouBVJrj7hQg2WBUZ88/view?usp=share_link)
- [AVE Dataset](https://drive.google.com/file/d/1EjsbGoFZ2mCHNeVYmf45Kb4tNwTLV86o/view?usp=share_link)
- Original Dataset homepage:https://sites.google.com/view/audiovisualresearch

## Contact
If you have any questions, please email s210068@wakayama-u.ac.jp
## Reference
Zhang, Jiwei, et al. "Variational Autoencoder with CCA for Audio-Visual Cross-Modal Retrieval." ACM Transactions on Multimedia Computing, Communications and Applications (2022).
